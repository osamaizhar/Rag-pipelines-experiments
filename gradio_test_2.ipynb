{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Excel and pdf parser and handling for multiple directories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API pcsk_4bLR9o_3crxHE9zjHW76VdRnBPi2Xo794pQnKSifnRfQ9iQc6U3iqeqeyVEZ3RjBPYtoD4\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from tkinter import scrolledtext, messagebox\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "import pinecone\n",
    "from pinecone import (\n",
    "    Pinecone,\n",
    "    ServerlessSpec,\n",
    "    CloudProvider,\n",
    "    AwsRegion,\n",
    "    VectorType\n",
    ")\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tkinter as tk\n",
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "import concurrent.futures\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Important: Import pinecone-client properly\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "PINECONE_API = os.getenv(\"PINECONE_API\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "print(\"PINECONE_API\", PINECONE_API)\n",
    "\n",
    "\n",
    "# Groq API settings\n",
    "GROQ_EMBED_URL = \"https://api.groq.com/openai/v1/embeddings\"\n",
    "GROQ_CHAT_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "EMBEDDING_MODEL = \"llama3-405b-8192-embed\"\n",
    "LLM_MODEL = \"llama3-70b-8192\"\n",
    "\n",
    "\n",
    "# Configure headers for Groq API requests\n",
    "GROQ_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "\n",
    "# documents = pdf_load_documents()\n",
    "# documents\n",
    "\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "#     \"\"\"Extract text from a PDF file.\"\"\"\n",
    "#     with open(pdf_path, 'r') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         text = \"\"\n",
    "#         for page_num in range(len(pdf_reader.pages)):\n",
    "#             page = pdf_reader.pages[page_num]\n",
    "#             text += page.extract_text() + \"\\n\"\n",
    "#     return text\n",
    "# extract_text_from_pdf(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF and Excel Parser (Maqbool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDF files: []\n",
      "Found Excel files: []\n",
      "Files parsed:\n",
      "\n",
      "Total documents loaded: 360\n"
     ]
    }
   ],
   "source": [
    "# def load_documents():\n",
    "#     documents = []\n",
    "\n",
    "#     # Load PDFs\n",
    "#     pdf_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "#     pdf_documents = pdf_loader.load()\n",
    "#     documents.extend(pdf_documents)\n",
    "\n",
    "#     # Load Excel files\n",
    "#     excel_files = glob.glob(os.path.join(DATA_PATH, \"*.xlsx\"))\n",
    "#     if excel_files:\n",
    "#         excel_documents = [pd.read_excel(file) for file in excel_files]\n",
    "#         documents.extend(excel_documents)\n",
    "\n",
    "#     if not documents:\n",
    "#         raise FileNotFoundError(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "\n",
    "#     return documents\n",
    "\n",
    "# # Load documents\n",
    "# documents = load_documents()\n",
    "\n",
    "# print(documents)\n",
    "# # Display the first document (PDF or Excel)\n",
    "# if isinstance(documents[0], pd.DataFrame):\n",
    "#     print(documents[0].head())  # Print first few rows if it's an Excel file\n",
    "# else:\n",
    "#     print(documents[0])  # Print the content if it's a PDF document\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    documents = []\n",
    "    file_names = []\n",
    "\n",
    "    # Load PDFs\n",
    "    pdf_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    pdf_documents = pdf_loader.load()\n",
    "    documents.extend(pdf_documents)\n",
    "    \n",
    "    # Get PDF filenames\n",
    "    pdf_files = glob.glob(os.path.join(DATA_PATH, \"*.pdf\"))\n",
    "    print(f\"Found PDF files: {pdf_files}\")  # Debug print\n",
    "    file_names.extend([os.path.basename(file) for file in pdf_files])\n",
    "\n",
    "    # Load Excel files\n",
    "    excel_files = glob.glob(os.path.join(DATA_PATH, \"*.xlsx\"))\n",
    "    print(f\"Found Excel files: {excel_files}\")  # Debug print\n",
    "    if excel_files:\n",
    "        for file in excel_files:\n",
    "            documents.append(pd.read_excel(file))\n",
    "            file_names.append(os.path.basename(file))\n",
    "\n",
    "    if not documents:\n",
    "        raise FileNotFoundError(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "\n",
    "    return documents, file_names\n",
    "\n",
    "# Load documents\n",
    "documents, file_names = load_documents()\n",
    "\n",
    "# Print file names\n",
    "print(\"Files parsed:\")\n",
    "for name in file_names:\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Directory Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load PDF and Excel files from DATA_PATH.\n",
    "    Returns a list of documents with content and metadata and a list of filenames.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    file_names = []\n",
    "\n",
    "    # Load PDFs\n",
    "    pdf_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "    for doc in pdf_docs:\n",
    "        documents.append({\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": {\"source\": doc.metadata.get(\"source\", \"unknown\"), \"file_type\": \"pdf\"}\n",
    "        })\n",
    "        file_names.append(doc.metadata.get(\"source\", \"unknown\"))\n",
    "\n",
    "    # Load Excel files\n",
    "    excel_files = glob.glob(os.path.join(DATA_PATH, \"*.xlsx\"))\n",
    "    for file in excel_files:\n",
    "        df = pd.read_excel(file)\n",
    "        headers = df.columns.tolist()\n",
    "        for _, row in df.iterrows():\n",
    "            content = \" \".join([f\"{col}: {str(row[col])}\" for col in headers])\n",
    "            documents.append({\n",
    "                \"content\": content,\n",
    "                \"metadata\": {\"source\": file, \"file_type\": \"excel\"}\n",
    "            })\n",
    "        file_names.append(file)\n",
    "\n",
    "    if not documents:\n",
    "        print(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "    return documents, file_names\n",
    "\n",
    "# Load documents\n",
    "documents, file_names = load_documents()\n",
    "\n",
    "# Print file names\n",
    "print(\"Files parsed:\")\n",
    "for name in file_names:\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Directory Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF DOCS len: \n",
      "\n",
      " 369\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Exam 01.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 01 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 02 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 03 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 04 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 05 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Meta Data - Assessments - Course 1.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Meta data - Ebooks Course 1.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Meta Data Lessons - Course 1.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\Meta Data - Videos C1.xlsx\n",
      "Loaded 130 documents\n",
      "Files parsed:\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Chapter 1 (Introduction to Surgical Technology).pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Chapter 2 (Communication and Teamwork).pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Chapter 3 (Medicolegal Aspects of Surgical Technology).pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Chapter 4 (Health Care Facility Structure and Environment).pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Chapter 5  (Supporting the Psychosocial Needs of the Patient).pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Lesson 01 - Surgical Technology The Profession and The Professional.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Lesson 02 - Communication and Teamwork.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Lesson 03 - Medicolegal Aspects of Surgical Technology.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Lesson 04 - Health Care Facility Structure and Environment.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Lesson 05 - Supporting the Psychosocial Needs of the Patient   .pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L1.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L1_Youtube.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L2.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L2_YouTube.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L3.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L4.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\C1L5.pdf\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Exam 01.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 01 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 02 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 03 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 04 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Lesson 05 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Assessments\\Meta Data - Assessments - Course 1.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Ebooks\\Meta data - Ebooks Course 1.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Lessons (PPTs)\\Meta Data Lessons - Course 1.xlsx\n",
      "- D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\Course 1 - Introduction to Surgical Technology\\Videos - Transcripts\\Meta Data - Videos C1.xlsx\n",
      "\n",
      "Total documents loaded: 130\n"
     ]
    }
   ],
   "source": [
    "# def load_documents():\n",
    "#     \"\"\"\n",
    "#     Load PDF and Excel files from DATA_PATH and its subdirectories.\n",
    "#     Returns a list of documents with content and metadata and a list of filenames.\n",
    "#     \"\"\"\n",
    "#     documents = []\n",
    "#     file_names_set = set()\n",
    "\n",
    "#     # Load PDFs from all subdirectories\n",
    "#     pdf_loader = PyPDFDirectoryLoader(DATA_PATH, recursive=True)\n",
    "#     pdf_docs = pdf_loader.load()\n",
    "#     for doc in pdf_docs:\n",
    "#         source = doc.metadata.get(\"source\", \"unknown\")\n",
    "#         if source not in file_names_set:\n",
    "#             documents.append({\n",
    "#                 \"content\": doc.page_content,\n",
    "#                 \"metadata\": {\"source\": source, \"file_type\": \"pdf\"}\n",
    "#             })\n",
    "#             file_names_set.add(source)\n",
    "\n",
    "#     # Load Excel files from all subdirectories\n",
    "#     for root, _, files in os.walk(DATA_PATH):\n",
    "#         for file in files:\n",
    "#             if file.endswith(\".xlsx\"):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 if file_path not in file_names_set:\n",
    "#                     df = pd.read_excel(file_path)\n",
    "#                     headers = df.columns.tolist()\n",
    "#                     for _, row in df.iterrows():\n",
    "#                         content = \" \".join([f\"{col}: {str(row[col])}\" for col in headers])\n",
    "#                         documents.append({\n",
    "#                             \"content\": content,\n",
    "#                             \"metadata\": {\"source\": file_path, \"file_type\": \"excel\"}\n",
    "#                         })\n",
    "#                     file_names_set.add(file_path)\n",
    "\n",
    "#     if not documents:\n",
    "#         print(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "#     else:\n",
    "#         print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "#     return documents, list(file_names_set)\n",
    "\n",
    "# # Load documents\n",
    "# documents, file_names = load_documents()\n",
    "\n",
    "# # Print file names\n",
    "# print(\"Files parsed:\")\n",
    "# for name in file_names:\n",
    "#     print(f\"- {name}\")\n",
    "\n",
    "# print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "# #documents\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load PDF and Excel files from DATA_PATH and its subdirectories.\n",
    "    Returns a list of documents with content and metadata, and a list of filenames.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    file_names = []\n",
    "    processed_files = []\n",
    "\n",
    "    # Load PDFs from all subdirectories\n",
    "    pdf_loader = PyPDFDirectoryLoader(DATA_PATH, recursive=True)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "    print(\"PDF DOCS len: \\n\\n\",len(pdf_docs))\n",
    "    #print(\"PDF DOCS: \\n\\n\",pdf_docs)\n",
    "    count = 0\n",
    "    for doc in pdf_docs:\n",
    "        source = doc.metadata.get(\"source\", \"unknown\")\n",
    "        if source not in processed_files:\n",
    "            documents.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": {\"source\": source, \"file_type\": \"pdf\"}\n",
    "            })\n",
    "            #print(f\"PARSED DATA {source}: \\n\",documents[-1])\n",
    "    \n",
    "            processed_files.append(source)\n",
    "            file_names.append(source)\n",
    "            #print(f\"Parsed PDF file : {source}\")\n",
    "        # print(\"COUNT: \", count)\n",
    "        count+=1\n",
    "   # return \n",
    "\n",
    "    # Load Excel files from all subdirectories\n",
    "    for root, _, files in os.walk(DATA_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file_path not in processed_files:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                    headers = df.columns.tolist()\n",
    "                    for _, row in df.iterrows():\n",
    "                        content = \" \".join([f\"{col}: {str(row[col])}\" for col in headers])\n",
    "                        documents.append({\n",
    "                            \"content\": content,\n",
    "                            \"metadata\": {\"source\": file_path, \"file_type\": \"excel\"}\n",
    "                        })\n",
    "                        #print(\"PARSED DATA: \\n\\n\\n\",documents[-1])\n",
    "                    processed_files.append(file_path)\n",
    "                    file_names.append(file_path)\n",
    "                    print(f\"Parsed Excel file: {file_path}\")\n",
    "\n",
    "    if not documents:\n",
    "        print(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(documents)} documents\")\n",
    "    # Print file names\n",
    "    print(\"Files parsed:\")\n",
    "    for name in processed_files:\n",
    "        print(f\"- {name}\")\n",
    "    return documents, file_names\n",
    "\n",
    "# Load documents\n",
    "documents, file_names = load_documents()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitting \\ Chunking using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def split_documents(documents):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         # Set a really small chunk size, just to show.\n",
    "#         chunk_size=800,\n",
    "#         chunk_overlap=80,\n",
    "#         length_function=len,\n",
    "#         is_separator_regex=False  # considers separators like '\\n\\n'if true\n",
    "#     )\n",
    "#     docs = text_splitter.split_documents(documents)\n",
    "#     return docs\n",
    "\n",
    "\n",
    "# chunks = split_documents(documents)\n",
    "# chunks \n",
    "\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False  # considers separators like '\\n\\n' if true\n",
    "    )\n",
    "    # Assuming each document is a dictionary with 'content' and 'metadata'\n",
    "    docs = []\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc['content'])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            docs.append({\n",
    "                \"content\": chunk,\n",
    "                \"metadata\": {\n",
    "                    **doc['metadata'],\n",
    "                    \"chunk_id\": i\n",
    "                }\n",
    "            })\n",
    "    return docs\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = split_documents(documents)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_4bLR9o_3crxHE9zjHW76VdRnBPi2Xo794pQnKSifnRfQ9iQc6U3iqeqeyVEZ3RjBPYtoD4\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API)\n",
    "print(PINECONE_API)\n",
    "\n",
    "\n",
    "#  --------------- initialize pinecone -----------------------------\n",
    "# pc.create_index_for_model(\n",
    "#     name=\"test-index\",\n",
    "#     cloud=\"aws\",\n",
    "#     region=\"us-east-1\",\n",
    "#     embed={\n",
    "#         \"model\":\"llama-text-embed-v2\",\n",
    "#         \"field_map\":{\"text\": \"page_content\"}\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use What:\n",
    "**Use Upsert:**\n",
    "\n",
    "When you're adding new vectors or want to replace existing vectors with new data (including changing the vector values).\n",
    "When you need to add a completely new document or vector.\n",
    "When you want to update both the vector values and metadata.\n",
    "\n",
    "**Use Update:**\n",
    "\n",
    "When you're only modifying the metadata of an existing vector.\n",
    "When the vector values (embeddings) themselves are correct and only extra information like text, author, or document-related metadata needs to be updated.\n",
    "Summary:\n",
    "Upsert: Adds or replaces both the vector values and metadata. Use when inserting or completely replacing data.\n",
    "Update: Modifies the metadata without changing the vector values. Use when the vectors are correct, but metadata needs an update.\n",
    "For your case, if you just want to add or update the page_content or any other metadata for existing vectors, use update. If you want to re-upload vectors with new embeddings or metadata, use upsert.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings Via AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en'  and Upsert each to Pinecone one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 1 upserted to Pinecone with metadata\n",
      "Embedding 2 upserted to Pinecone with metadata\n",
      "Embedding 3 upserted to Pinecone with metadata\n",
      "Embedding 4 upserted to Pinecone with metadata\n",
      "Embedding 5 upserted to Pinecone with metadata\n",
      "Embedding 6 upserted to Pinecone with metadata\n",
      "Embedding 7 upserted to Pinecone with metadata\n",
      "Embedding 8 upserted to Pinecone with metadata\n",
      "Embedding 9 upserted to Pinecone with metadata\n",
      "Embedding 10 upserted to Pinecone with metadata\n",
      "Embedding 11 upserted to Pinecone with metadata\n",
      "Embedding 12 upserted to Pinecone with metadata\n",
      "Embedding 13 upserted to Pinecone with metadata\n",
      "Embedding 14 upserted to Pinecone with metadata\n",
      "Embedding 15 upserted to Pinecone with metadata\n",
      "Embedding 16 upserted to Pinecone with metadata\n",
      "Embedding 17 upserted to Pinecone with metadata\n",
      "Embedding 18 upserted to Pinecone with metadata\n",
      "Embedding 19 upserted to Pinecone with metadata\n",
      "Embedding 20 upserted to Pinecone with metadata\n",
      "Embedding 21 upserted to Pinecone with metadata\n",
      "Embedding 22 upserted to Pinecone with metadata\n",
      "Embedding 23 upserted to Pinecone with metadata\n",
      "Embedding 24 upserted to Pinecone with metadata\n",
      "Embedding 25 upserted to Pinecone with metadata\n",
      "Embedding 26 upserted to Pinecone with metadata\n",
      "Embedding 27 upserted to Pinecone with metadata\n",
      "Embedding 28 upserted to Pinecone with metadata\n",
      "Embedding 29 upserted to Pinecone with metadata\n",
      "Embedding 30 upserted to Pinecone with metadata\n",
      "Embedding 31 upserted to Pinecone with metadata\n",
      "Embedding 32 upserted to Pinecone with metadata\n",
      "Embedding 33 upserted to Pinecone with metadata\n",
      "Embedding 34 upserted to Pinecone with metadata\n",
      "Embedding 35 upserted to Pinecone with metadata\n",
      "Embedding 36 upserted to Pinecone with metadata\n",
      "Embedding 37 upserted to Pinecone with metadata\n",
      "Embedding 38 upserted to Pinecone with metadata\n",
      "Embedding 39 upserted to Pinecone with metadata\n",
      "Embedding 40 upserted to Pinecone with metadata\n",
      "Embedding 41 upserted to Pinecone with metadata\n",
      "Embedding 42 upserted to Pinecone with metadata\n",
      "Embedding 43 upserted to Pinecone with metadata\n",
      "Embedding 44 upserted to Pinecone with metadata\n",
      "Embedding 45 upserted to Pinecone with metadata\n",
      "Embedding 46 upserted to Pinecone with metadata\n",
      "Embedding 47 upserted to Pinecone with metadata\n",
      "Embedding 48 upserted to Pinecone with metadata\n",
      "Embedding 49 upserted to Pinecone with metadata\n",
      "Embedding 50 upserted to Pinecone with metadata\n",
      "Embedding 51 upserted to Pinecone with metadata\n",
      "Embedding 52 upserted to Pinecone with metadata\n",
      "Embedding 53 upserted to Pinecone with metadata\n",
      "Embedding 54 upserted to Pinecone with metadata\n",
      "Embedding 55 upserted to Pinecone with metadata\n",
      "Embedding 56 upserted to Pinecone with metadata\n",
      "Embedding 57 upserted to Pinecone with metadata\n",
      "Embedding 58 upserted to Pinecone with metadata\n",
      "Embedding 59 upserted to Pinecone with metadata\n",
      "Embedding 60 upserted to Pinecone with metadata\n",
      "Embedding 61 upserted to Pinecone with metadata\n",
      "Embedding 62 upserted to Pinecone with metadata\n",
      "Embedding 63 upserted to Pinecone with metadata\n",
      "Embedding 64 upserted to Pinecone with metadata\n",
      "Embedding 65 upserted to Pinecone with metadata\n",
      "Embedding 66 upserted to Pinecone with metadata\n",
      "Embedding 67 upserted to Pinecone with metadata\n",
      "Embedding 68 upserted to Pinecone with metadata\n",
      "Embedding 69 upserted to Pinecone with metadata\n",
      "Embedding 70 upserted to Pinecone with metadata\n",
      "Embedding 71 upserted to Pinecone with metadata\n",
      "Embedding 72 upserted to Pinecone with metadata\n",
      "Embedding 73 upserted to Pinecone with metadata\n",
      "Embedding 74 upserted to Pinecone with metadata\n",
      "Embedding 75 upserted to Pinecone with metadata\n",
      "Embedding 76 upserted to Pinecone with metadata\n",
      "Embedding 77 upserted to Pinecone with metadata\n",
      "Embedding 78 upserted to Pinecone with metadata\n",
      "Embedding 79 upserted to Pinecone with metadata\n",
      "Embedding 80 upserted to Pinecone with metadata\n",
      "Embedding 81 upserted to Pinecone with metadata\n",
      "Embedding 82 upserted to Pinecone with metadata\n",
      "Embedding 83 upserted to Pinecone with metadata\n",
      "Embedding 84 upserted to Pinecone with metadata\n",
      "Embedding 85 upserted to Pinecone with metadata\n",
      "Embedding 86 upserted to Pinecone with metadata\n",
      "Embedding 87 upserted to Pinecone with metadata\n",
      "Embedding 88 upserted to Pinecone with metadata\n",
      "Embedding 89 upserted to Pinecone with metadata\n",
      "Embedding 90 upserted to Pinecone with metadata\n",
      "Embedding 91 upserted to Pinecone with metadata\n",
      "Embedding 92 upserted to Pinecone with metadata\n",
      "Embedding 93 upserted to Pinecone with metadata\n",
      "Embedding 94 upserted to Pinecone with metadata\n",
      "Embedding 95 upserted to Pinecone with metadata\n",
      "Embedding 96 upserted to Pinecone with metadata\n",
      "Embedding 97 upserted to Pinecone with metadata\n",
      "Embedding 98 upserted to Pinecone with metadata\n",
      "Embedding 99 upserted to Pinecone with metadata\n",
      "Embedding 100 upserted to Pinecone with metadata\n",
      "Embedding 101 upserted to Pinecone with metadata\n",
      "Embedding 102 upserted to Pinecone with metadata\n",
      "Embedding 103 upserted to Pinecone with metadata\n",
      "Embedding 104 upserted to Pinecone with metadata\n",
      "Embedding 105 upserted to Pinecone with metadata\n",
      "Embedding 106 upserted to Pinecone with metadata\n",
      "Embedding 107 upserted to Pinecone with metadata\n",
      "Embedding 108 upserted to Pinecone with metadata\n",
      "Embedding 109 upserted to Pinecone with metadata\n",
      "Embedding 110 upserted to Pinecone with metadata\n",
      "Embedding 111 upserted to Pinecone with metadata\n",
      "Embedding 112 upserted to Pinecone with metadata\n",
      "Embedding 113 upserted to Pinecone with metadata\n",
      "Embedding 114 upserted to Pinecone with metadata\n",
      "Embedding 115 upserted to Pinecone with metadata\n",
      "Embedding 116 upserted to Pinecone with metadata\n",
      "Embedding 117 upserted to Pinecone with metadata\n",
      "Embedding 118 upserted to Pinecone with metadata\n",
      "Embedding 119 upserted to Pinecone with metadata\n",
      "Embedding 120 upserted to Pinecone with metadata\n",
      "Embedding 121 upserted to Pinecone with metadata\n",
      "Embedding 122 upserted to Pinecone with metadata\n",
      "Embedding 123 upserted to Pinecone with metadata\n",
      "Embedding 124 upserted to Pinecone with metadata\n",
      "Embedding 125 upserted to Pinecone with metadata\n",
      "Embedding 126 upserted to Pinecone with metadata\n",
      "Embedding 127 upserted to Pinecone with metadata\n",
      "Embedding 128 upserted to Pinecone with metadata\n",
      "Embedding 129 upserted to Pinecone with metadata\n",
      "Embedding 130 upserted to Pinecone with metadata\n",
      "Embedding 131 upserted to Pinecone with metadata\n",
      "Embedding 132 upserted to Pinecone with metadata\n",
      "Embedding 133 upserted to Pinecone with metadata\n",
      "Embedding 134 upserted to Pinecone with metadata\n",
      "Embedding 135 upserted to Pinecone with metadata\n",
      "Embedding 136 upserted to Pinecone with metadata\n",
      "Embedding 137 upserted to Pinecone with metadata\n",
      "Embedding 138 upserted to Pinecone with metadata\n",
      "Embedding 139 upserted to Pinecone with metadata\n",
      "Embedding 140 upserted to Pinecone with metadata\n",
      "Embedding 141 upserted to Pinecone with metadata\n",
      "Embedding 142 upserted to Pinecone with metadata\n",
      "Embedding 143 upserted to Pinecone with metadata\n",
      "Embedding 144 upserted to Pinecone with metadata\n",
      "Embedding 145 upserted to Pinecone with metadata\n",
      "Embedding 146 upserted to Pinecone with metadata\n",
      "Embedding 147 upserted to Pinecone with metadata\n",
      "All 147 embeddings have been upserted to Pinecone\n"
     ]
    }
   ],
   "source": [
    "# Connect to the index\n",
    "index = pc.Index(\"ai-coach\")\n",
    "#index = pc.Index(\"ahsan-400pg-pdf-doc-test\")\n",
    "\n",
    "\n",
    "embedding_model = AutoModel.from_pretrained(\n",
    "    'jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
    "# user_query = \"user query\"\n",
    "# Function to generate embeddings without tokenization\n",
    "\n",
    "\n",
    "def get_embedding(data):\n",
    "    embeddings = embedding_model.encode(data).tolist()\n",
    "    return embeddings\n",
    "\n",
    "# def upsert_chunks_to_pinecone(index, chunks):\n",
    "#   count = 1\n",
    "#   for chunk in chunks:\n",
    "#     #embedding = embedding_model.encode(chunk.page_content).tolist()\n",
    "#     embedding = get_embedding(chunk.page_content)\n",
    "#     # Extract metadata\n",
    "#     metadata = chunk.metadata\n",
    "#     text = chunk.page_content\n",
    "#     # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "#     vector_id = f\"vec_{count}\"\n",
    "\n",
    "#     # Upsert the embedding along with its metadata\n",
    "#     index.upsert(vectors=[(vector_id, embedding, metadata, text)])\n",
    "\n",
    "#     print(f\"Embedding {count} upserted to Pinecone with metadata\")\n",
    "#     count += 1\n",
    "#       # Ensure data is written immediately\n",
    "#   print(f\"All {count} Embeddings have been upserted to pinecone\")\n",
    "\n",
    "\n",
    "# def upsert_chunks_to_pinecone(index, chunks):\n",
    "#     count = 1\n",
    "#     for chunk in chunks:\n",
    "#         # Get the embedding for the chunk\n",
    "#         embedding = get_embedding(chunk.page_content)\n",
    "\n",
    "#         # Extract metadata and add text as part of the metadata\n",
    "#         metadata = chunk.metadata\n",
    "#         metadata[\"text\"] = chunk.page_content  # Store text in metadata\n",
    "\n",
    "#         # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "#         vector_id = f\"vec_{count}\"\n",
    "\n",
    "#         # Upsert the embedding along with its metadata\n",
    "#         index.upsert(vectors=[(vector_id, embedding, metadata)])\n",
    "\n",
    "#         print(f\"Embedding {count} upserted to Pinecone with metadata\")\n",
    "#         count += 1\n",
    "\n",
    "#     print(f\"All {count-1} Embeddings have been upserted to Pinecone\")\n",
    "\n",
    "\n",
    "# upsert_chunks_to_pinecone(index, chunks)\n",
    "\n",
    "def upsert_chunks_to_pinecone(index, chunks):\n",
    "    count = 1\n",
    "    for chunk in chunks:\n",
    "        # Ensure the chunk has the correct structure\n",
    "        content = chunk.get('content')\n",
    "        metadata = chunk.get('metadata', {})\n",
    "\n",
    "        # Get the embedding for the chunk\n",
    "        embedding = get_embedding(content)\n",
    "\n",
    "        # Add the text as part of the metadata\n",
    "        metadata['text'] = content  # Store text in metadata\n",
    "\n",
    "        # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "        vector_id = f\"vec_{count}\"\n",
    "\n",
    "        # Upsert the embedding along with its metadata\n",
    "        index.upsert(vectors=[(vector_id, embedding, metadata)])\n",
    "\n",
    "        print(f\"Embedding {count} upserted to Pinecone with metadata\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"All {count-1} embeddings have been upserted to Pinecone\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming `index` is your Pinecone index and `chunks` is the list of chunked documents\n",
    "upsert_chunks_to_pinecone(index, chunks)\n",
    "\n",
    "# query_embeddings = embedding_model.encode(user_query).tolist()\n",
    "# query_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Vectors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pinecone_chunks(index, chunks):\n",
    "    count = 1\n",
    "    for chunk in chunks:\n",
    "        # Get updated embedding\n",
    "        embedding = get_embedding(chunk.page_content)\n",
    "\n",
    "        # Extract metadata and page content\n",
    "        metadata = chunk.metadata\n",
    "        text = chunk.page_content\n",
    "\n",
    "        # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "        vector_id = f\"vec_{count}\"\n",
    "\n",
    "        # Update the embedding and metadata\n",
    "        index.update(id=vector_id, values=embedding, set_metadata=metadata)\n",
    "\n",
    "        print(f\"Embedding {count} updated in Pinecone with new metadata\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"All {count-1} embeddings have been updated in Pinecone\")\n",
    "\n",
    "# update_pinecone_chunks(index, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since your application is designed to answer a wide range of student queries and suggest relevant material, you want to retrieve enough content to cover different facets of a topic without overwhelming the LLM with too much information.\n",
    "\n",
    "# Starting Point:\n",
    "- A common starting point is to set top_k between **5 and 10.**\n",
    "- **top_k=5:** This can work well if your curated content is highly relevant and precise, ensuring that the top 5 matches are very close to the query.\n",
    "-  **top_k=10:** If you want the coach to consider a broader range of content—perhaps to provide diverse perspectives or cover a topic more comprehensively—increasing top_k to around 10 might be beneficial.\n",
    "\n",
    "# Experiment and Adjust:\n",
    "- The “best” value depends on factors such as the diversity of your content, how densely your data covers the topics, and the quality of the embedding matches. It’s a good idea to experiment with different top_k values and evaluate the quality and relevance of the responses in your specific\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Pinecone index using embeddings\n",
    "def query_pinecone(embedding):\n",
    "    # Use keyword arguments to pass the embedding and other parameters\n",
    "    result = index.query(vector=embedding, top_k=20, include_metadata=True)\n",
    "    return result['matches']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Groq Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Groq LLM\n",
    "def query_groq(prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        GROQ_CHAT_URL,\n",
    "        headers=GROQ_HEADERS,\n",
    "        json={\n",
    "            \"model\": LLM_MODEL,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 8192  # max from groq website\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error querying Groq: {response.text}\")\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Tokenizer to count number of tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v2-base-en\")\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    # Encode the text into tokens\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process User Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio GUI TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\AppData\\Local\\Temp\\ipykernel_3920\\262375163.py:208: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(height=500)\n",
      "d:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\env\\Lib\\site-packages\\gradio\\layouts\\column.py:55: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://ea159ff23b0ef964fa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ea159ff23b0ef964fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query Tokens: 12\n",
      "CONTEXT: History\tof\tSurgical\tTechnology\n",
      "(0:08\t-\t0:20)\n",
      "Hello\teveryone,\tand\twelcome\tback\tto\tour\tchannel.\tA\twhile\tago,\twe\tmade\ta\tvideo\ton\tthe\thistory\n",
      "of\tsurgery.\tIf\tyou\thaven't\twatched\tthat,\tgo\tdo\tit\tafter\tthis,\twhich\tyou\tall\tloved,\tso\twe\tthought\n",
      "we'd\tmake\tmore\tsurgery-related\tcontent\tfor\tyou\tguys.\n",
      "(0:21\t-\t0:32)\n",
      "That\tis\twhy\ttoday\twe\thave\ta\tvideo\ton\tthe\thistory\tof\tsurgical\ttechnology.\tIt's\tall\tstupid\n",
      "interesting,\tand\twe'll\tbe\ttalking\tabout\ta\trole\tin\thospitals\tthat\tis\tso\timportant,\tbut\talso\tso\n",
      "underrated.\tSo,\tlet's\tbegin.\n",
      "(0:33\t-\t0:48)\n",
      "To\tthe\toperating\ttheatre,\tdon't\tforget\tyour\tgloves.\tWhat\tis\tsurgical\ttechnology?\tTo\tstart\toff\n",
      "with,\tlet's\tunderstand\twhat\tsurgical\ttechnology\tis.\tYou\tmight\thear\tthe\tword\ttechnology\tand\n",
      "think\tabout\tcool\tgadgets\tand\tsmart\tsystems,\tbut\tthat's\tnot\texactly\tright.\n",
      "(0:48\t-\t1:07)\n",
      "Medicolegal Aspects of \n",
      "Surgical Technology\n",
      "C1L5\t-\tAshley\tHay\n",
      "(0:06\t-\t0:18)\n",
      "Welcome\tback.\tWe\tare\ton\tthe\tlast\tlesson\tfor\tcourse\tone.\tSo\tcourse\tone,\tlesson\tfive,\twe're\n",
      "gonna\tlook\tat\tsupporting\tthe\tpsychosocial\tneeds\tof\tthe\tpatient,\treally\timportant.\n",
      "(0:19\t-\t0:50)\n",
      "And\tas\ta\tsurgical\ttech,\tyou\treally\tcontribute\tto\tthe\tpatient's\twellbeing\toverall.\tSo\tnot\tonly\tdo\n",
      "you\thelp\tfor\ttheir\tphysical\thealth,\tyou\talso\thelp\tfor\ttheir\tpsychological\thealth\tas\twell.\tSo\tjust\n",
      "realising\tthat\twhile\tthis\tis\tyour\tjob\tand\tyou\tshow\tup\tevery\tday,\tday\tto\tday\tand\tsee\tpatients\tin\n",
      "and\tout\tand\tyou\tfeel\tit's\tvery\teasy\tand\tnormal,\tjust\tkind\tof\tget\tthem\tin\tand\tget\tthem\tout\tand\n",
      "everything\tturns\tout\tgreat.\n",
      "(0:50\t-\t1:06)\n",
      "You\thave\tto\trealise\tthat\tfor\tthis\tpatient,\tit\tis\tvery\tmuch\ta\ttraumatic\tand\tsometimes\ta\tlife-\n",
      "(0:48\t-\t1:07)\n",
      "Surgical\ttechnology\tis\ta\tfield\tof\tmedicine\tstudied\tand\tpractised\tby\thealth\tprofessionals\twho\n",
      "work\tas\ta\tteam\tto\tdeliver\tsurgical\tcare.\tSurgical\ttechnologists,\talso\tknown\tas\tsurgical\n",
      "technicians,\tor\tmore\tcommonly\tas\tscrubs,\tremember\tthe\tTV\tshow.\tThey\tare\tmembers\tof\tan\n",
      "operating\troom\tteam\twho\twork\tunder\tthe\tauthority\tof\ta\tsurgeon.\n",
      "(1:07\t-\t1:28)\n",
      "They're\tpart\tof\ta\tfive-member\tteam\twhich\tincludes\ta\tcirculating\tnurse,\tsurgical\tresident\tor\tfirst\n",
      "assistant,\tan\tanesthesiologist,\tand\tof\tcourse\tthe\tsurgeon.\tThese\ttechnologists\thave\ta\tnumber\n",
      "of\tdifferent\troles\tand\tresponsibilities,\tand\twe'll\tquickly\tgo\tover\tthem\tbefore\twe\tget\tinto\tthe\n",
      "history\tof\ttheir\tprofession.\tSurgical\ttechnologists\tare\tcrucial\tat\tevery\tstep\tof\tthe\tsurgery\n",
      "process.\n",
      "(1:29\t-\t2:06)\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L5 Topic: Supporting the psychosocial needs of the patient Description: This lesson emphasizes the importance of addressing patients' psychosocial needs in surgery through empathy, active listening, and reassurance. It discusses common patient fears, the role of communication, and Maslow’s hierarchy of needs in understanding and supporting patients emotionally. Keywords: psychosocial needs, patient care, empathy, active listening, reassurance, Maslow’s hierarchy, surgical anxiety, therapeutic communication, patient fears, emotional support\n",
      "Course Name: Introduction to Surgical Technology File Name: Chapter 2 (Communication and Teamwork)\n",
      "\n",
      "\n",
      " Topic: Chapter 2: Communication and Teamwork\n",
      "\n",
      "\n",
      " Description: Examine critical elements and barriers of effective\n",
      "communication, types of verbal abuse, problematic workplace\n",
      "behaviors, teamwork, and the utilization of computers in the\n",
      "perioperative environment. Keywords: Communication, Teamwork, Verbal Communication, Nonverbal Communication, Conflict Resolution, Active Listening, Cultural Competence, Patient Safety, Surgical Team, Workplace Behavior​\n",
      "Course Name: Introduction to Surgical Technology File Name: Chapter 03 (Medicolegal Aspects Of Surgical\n",
      "Technology)\n",
      " Topic: Chapter 03: Medicolegal Aspects Of Surgical\n",
      "Technology\n",
      " Description: Learn to distinguish between laws, standards, and codes of\n",
      "conduct, understand risk management, licensure, and\n",
      "certification, recognize abuse and violence, define sentinel\n",
      "events, and explore negligence, documentation, informed\n",
      "consent, and legal documents in the perioperative environment. Keywords: Medical Law, Surgical Negligence, Informed Consent, HIPAA, Patient Rights, Risk Management, Sentinel Events, Universal Protocol, Workplace Harassment, Documentation​\n",
      "with\tthe\tsurgeon,\tassisting\tin\tsurgery,\tpassing\tinstruments,\tsutures,\tand\tany\tother\tdevices\tthat\n",
      "the\tsurgeon\tmay\tneed\tthroughout\ta\tprocedure.\n",
      "(2:04\t-\t2:40)\n",
      "Other\ttimes,\twe\tmay\tbe\tactually\tassisting\tthat\tsurgeon\twith\tretracting\ttissue\tand\thelping\tout\n",
      "throughout\tthe\tprocedure.\tOur\tjobs\tin\tthe\tOR\trevolve\taround\texcellence\tin\tpatient\tcare,\twith\n",
      "our\tassociation's\tmotto\tbeing\tagar\tprimo,\twhich\tin\tEnglish\tmeans\tthe\tpatient\tfirst.\tWhen\tit\n",
      "comes\tto\tthe\toperating\troom,\tyou\tmay\thave\tone\tsurgeon\tfixing\tyou,\tbut\tit\ttakes\ta\tteam\tto\tsee\n",
      "it\tthrough\tfrom\tstart\tto\tfinish,\tand\ta\tsurgical\ttechnologist\tis\tan\tintegral\tmember\tof\tthat\tteam.\n",
      "(3:02\t-\t3:04)\n",
      "For\tmore\tinformation,\tvisit\twww.FEMA.gov\n",
      "Course Name: Introduction to Surgical Technology File Name: Lesson 03 - Medicolegal Aspects Of Surgical\n",
      "Technology\n",
      " Topic: Medicolegal Aspects Of Surgical\n",
      "Technology\n",
      " Description: Learn to distinguish between laws, standards, and codes of conduct, understand risk management, licensure, and certification, recognize abuse and violence, define sentinel\n",
      "events, and explore negligence, documentation, informed consent, and legal documents in the perioperative environment. Keywords: Medical Law, Surgical Negligence, Informed Consent, HIPAA, Patient Rights, Risk Management, Sentinel Events, Universal Protocol, Workplace Harassment, Documentation​\n",
      "C1L1\t-\tAshley\tHay\n",
      "(0:05\t-\t5:41)\n",
      "Hello,\twelcome\tback.\tSo\twe\talready\tjust\tkind\tof\tbriefly\tcovered\tthe\tintroduction\tto\twhat\tthis\n",
      "course\tmight\tinclude,\tbut\tnow\tI\twould\tlike\tto\tjust\tgo\tand\tdive\tin\ta\tlittle\tbit\tdeeper.\tSo\tstarting\n",
      "with\tcourse\tone,\tlesson\tone,\twe\tgive\tjust\tkind\tof\ta\tbrief\tintroduction\tto\tthe\tprofession\tof\n",
      "surgical\ttechnology\tand\twhat\tthat\twill\tlook\tlike\tfor\tyou\tas\ta\tprofessional.\n",
      "We\tdid\tgo\tover\tbriefly\tsome\tkind\tof,\tyou\tknow,\tjust\tthe\thistory\tof\tthe\tprofession\tin\tgeneral,\tand\n",
      "then\talso\tsome\torganisations.\tAnd\twhile\tI\tthink\tthe\thistory\tof\thow\tthe\tsurgical\ttechnologist\n",
      "came\tto\tbe\tis\treally\tinteresting\tand\tdefinitely\timportant\tto\tknow,\tyou\tknow,\ta\tbit\tof\tyour\n",
      "background\tand\tkind\tof\twhat\tyou're\tgoing\tto\tbe\tpractising\tand\thow\tall\tof\tthat\tcame\tabout.\tI\n",
      "Course Name: Introduction to Surgical Technology File Name: Lesson - 02 Quiz\n",
      " Topic: Communication and Teamwork Description: Examine critical elements and barriers of effective\n",
      "communication, types of verbal abuse, problematic workplace\n",
      "behaviors, teamwork, and the utilization of computers in the\n",
      "perioperative environment. Keywords: nan\n",
      "Course Name: Introduction to Surgical Technology File Name: Lesson - 02 Communication and Teamwork Topic: Communication and Teamwork Description: Examine critical elements and barriers of effective communication, types of verbal abuse, problematic workplace behaviors, teamwork, and the utilization of computers in the\n",
      "perioperative environment. Keywords: Communication, Teamwork, Verbal Communication, Non-Verbal Communication, Cultural Competence, Conflict Resolution, Active Listening, Patient Safety, Workplace Behavior, Surgical Team​\n",
      "Course Name: Introduction to Surgical Technology File Name: Chapter 05 (Supporting The Psychosocial\n",
      "Needs Of The Patient)\n",
      "\n",
      "\n",
      "\n",
      " Topic: Chapter 05: Supporting The Psychosocial\n",
      "Needs Of The Patient\n",
      "\n",
      "\n",
      "\n",
      " Description: Define patient-centered and outcome-oriented care, understand\n",
      "human needs based on Maslow’s hierarchy and Roger’s theory,\n",
      "recognize preoperative patient fears, the role of spirituality, and\n",
      "psychosocial care for special needs patients in the perioperative\n",
      "environment. Keywords: Patient-Centered Care, Maslow’s Hierarchy, Preoperative Anxiety, Emotional Support, Cultural Sensitivity, Special Patient Populations, Stress Management, Spiritual Care, Therapeutic Communication, Health Equity\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L1_YouTube Topic: History of Surgical Technology Description: This video explores the history of surgical technology, highlighting the evolution of surgical technologists from ancient times to modern-day certified professionals. It discusses their critical role in operating rooms, contributions during wartime, and their impact on global healthcare. Keywords: surgical technology, operating room, surgical technologists, history of surgery, World War medical advances, Operating Room Technician, surgical procedures, medical certification, perioperative care, healthcare evolution\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L3 Topic: Medicolegal aspects of surgical technology Description:  This lesson covers the medicolegal aspects of surgical technology, including federal and state laws, liability types, malpractice, informed consent, and patient rights. It highlights key policies, documentation requirements, and the importance of legal awareness in ensuring patient safety and professional accountability. Keywords: medicolegal, liability, malpractice, informed consent, patient rights, healthcare law, documentation, legal policies, professional accountability, surgical technology\n",
      "Course Name: Introduction to Surgical Technology File Name: Lesson - 03 Quiz\n",
      " Topic: Medicolegal Aspects Of Surgical\n",
      "Technology\n",
      " Description: Learn to distinguish between laws, standards, and codes of\n",
      "conduct, understand risk management, licensure, and\n",
      "certification, recognize abuse and violence, define sentinel\n",
      "events, and explore negligence, documentation, informed\n",
      "consent, and legal documents in the perioperative environment. Keywords: nan\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L2 Topic: Communication and Teamwork Description: This lesson explores the importance of communication and teamwork in healthcare, emphasizing effective communication strategies, active listening, and overcoming barriers like misperceptions and environmental challenges. It highlights the role of communication in leadership, team dynamics, and patient interactions for improved healthcare outcomes. Keywords: communication, teamwork, healthcare, active listening, leadership, misperceptions, verbal blocking, patient interaction, communication barriers, team dynamics\n",
      "available\tto\thelp\tyou.\tOne\tthat\tI'd\treally\tlike\tto\tpoint\tout\tis\tthe\tAssociation\tof\tSurgical\n",
      "Technologists.\tThat's\tAST.\n",
      "That\tone\tis\tright\there,\tthe\tblue\tand\tblack\tlogo.\tSo\tthis\tis\ta\tspecific\torganisation\tin\tsurgical\n",
      "technology.\tThey\tprovide\tforums\tfor\tlearning,\tdiscussion\tand\tadvocacy,\tas\twell\tas\ttraining\tand\n",
      "curriculum\tdevelopment,\tand\tthey\tadvocate\tfor\tstandards\tin\tpatient\tcare.\n",
      "So\tlooking\tat\tall\tthat\tthis\torganisation\thas\tto\toffer\tis\tdefinitely\thelpful\tto\tyou.\tYou\tshould\n",
      "definitely,\tyou\tknow,\tvisit\ttheir\twebsite\tand\tsee\twhat\tthey\thave\tto\toffer.\tAnd\tthen\tthere's\ta\tfew\n",
      "other\tones\there.\n",
      "The\tNational\tBoard\tof\tSurgical\tTechnology\tand\tSurgical\tAssisting,\tthat's\tabbreviated\tNBSTSA,\n",
      "and\tthat's\tthis\tfirst\tone\ton\tthe\tleft\there,\tthe\tblue\tand\tred\ticon,\tand\tthey\tare\ta\tcertifying\tbody\n",
      "Course Name: Introduction to Surgical Technology File Name: Lesson - 05 Quiz\n",
      " Topic: Supporting The Psychosocial\n",
      "Needs Of The Patient\n",
      "\n",
      "\n",
      "\n",
      " Description: Define patient-centered and outcome-oriented care, understand\n",
      "human needs based on Maslow’s hierarchy and Roger’s theory,\n",
      "recognize preoperative patient fears, the role of spirituality, and\n",
      "psychosocial care for special needs patients in the perioperative\n",
      "environment. Keywords: nan\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L4 Topic: Healthcare facility structure and environment Description: This lesson covers the structure and environment of healthcare facilities, focusing on operating room design, infection control, and efficiency. It highlights different facility layouts, surgical equipment, and furniture, emphasizing their roles in patient safety, workflow optimization, and maintaining sterile conditions. Keywords: healthcare facility, operating room design, infection control, sterile environment, surgical equipment, efficiency, perioperative care, surgical tables, workflow optimization, patient safety\n",
      "Response Tokens: 352\n"
     ]
    }
   ],
   "source": [
    "# system_message = f\"\"\"\n",
    "#     You are a knowledgeable and friendly coach. Your goal is to help students understand concepts in a detailed and easy-to-understand manner. \n",
    "#     Be patient, ask guiding questions, and provide step-by-step explanations where needed. Adapt your responses to the student's knowledge level \n",
    "#     and help them build confidence in their learning. Refer relevant material to the student and encourage them to explore further.\n",
    "\n",
    "#     Based on the context and the student's question, provide a thoughtful and detailed explanation. Encourage them to think about the topic and \n",
    "#     offer further guidance if needed.\n",
    "#     \"\"\"\n",
    "\n",
    "# def gradio_interface(prompt,history =[]):\n",
    "#     output = process_user_query(prompt,history)\n",
    "#     history.append((prompt,output))\n",
    "#     return history\n",
    "\n",
    "# gr.Interface(fn=gradio_interface, inputs= ['text',\"state\"], outputs=[\"chatbot\",\"state\"]).launch(debug=True,share=True)\n",
    "    \n",
    "\n",
    "# ------------------------------------------- WORKING 1 -------------------------------------------\n",
    "\n",
    "# # Function to be used by Gradio for handling the query\n",
    "# def gradio_process(user_query):\n",
    "#     response = process_user_query(user_query, conversation_history)\n",
    "#     return response\n",
    "\n",
    "# # Create Gradio interface\n",
    "# interface = gr.Interface(fn=gradio_process, inputs=\"text\", outputs=\"text\", title=\"RAG-based Coaching System\")\n",
    "\n",
    "# # Launch Gradio app\n",
    "# interface.launch()\n",
    "# ------------------------------------------- WORKING 2 -------------------------------------------\n",
    "\n",
    "# Initialize empty conversation history (list of tuples)\n",
    "# conversation_history = []\n",
    "\n",
    "# def process_user_query(user_query: str, conversation_history: list):\n",
    "#     print(f\"User Query Tokens: {count_tokens(user_query)}\")\n",
    "\n",
    "#     # Generate embedding and get relevant context\n",
    "#     embedding = get_embedding(user_query)\n",
    "#     relevant_chunks = query_pinecone(embedding)\n",
    "#     context = \"\\n\".join(chunk['metadata'][\"text\"] for chunk in relevant_chunks)\n",
    "#     print(\"CONTEXT:\", context)\n",
    "\n",
    "#     # Format conversation history for the prompt\n",
    "#     history_str = \"\\n\".join(\n",
    "#         f\"User: {user}\\nCoach: {response}\" \n",
    "#         for user, response in conversation_history\n",
    "#     )\n",
    "\n",
    "#     # Create structured prompt\n",
    "#     prompt = f\"\"\"You are a knowledgeable and friendly coach. Follow these guidelines:\n",
    "#     1. Provide clear, step-by-step explanations\n",
    "#     2. Ask guiding questions to encourage critical thinking\n",
    "#     3. Adapt to the student's knowledge level\n",
    "#     4. Use examples from the provided context when relevant\n",
    "\n",
    "#     Context from learning materials:\n",
    "#     {context}\n",
    "\n",
    "#     Conversation history:\n",
    "#     {history_str}\n",
    "\n",
    "#     New student question:\n",
    "#     \"{user_query}\"\n",
    "\n",
    "#     Provide a helpful response:\"\"\"\n",
    "\n",
    "#     # Get LLM response\n",
    "#     groq_response = query_groq(prompt)\n",
    "#     print(f\"Response Tokens: {count_tokens(groq_response)}\")\n",
    "\n",
    "#     # Return updated history with new interaction\n",
    "#     return conversation_history + [(user_query, groq_response)]\n",
    "\n",
    "# # Gradio Interface\n",
    "# with gr.Blocks() as interface:\n",
    "#     gr.Markdown(\"# 🧑‍🏫 AI Coaching Assistant\")\n",
    "#     gr.Markdown(\"Welcome! I'm here to help you learn. Type your question below.\")\n",
    "    \n",
    "#     # State management\n",
    "#     chat_history = gr.State(conversation_history)\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         chatbot = gr.Chatbot(height=500)\n",
    "#         with gr.Column(scale=0.5):\n",
    "#             context_display = gr.Textbox(label=\"Relevant Context\", interactive=False)\n",
    "\n",
    "#     user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type here...\")\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "#         undo_btn = gr.Button(\"Undo Last\")\n",
    "#         clear_btn = gr.Button(\"Clear History\")\n",
    "\n",
    "#     def handle_submit(user_input, history):\n",
    "#         if not user_input.strip():\n",
    "#             return gr.update(), history, \"\"\n",
    "        \n",
    "#         # Process query and update history\n",
    "#         new_history = process_user_query(user_input, history)\n",
    "        \n",
    "#         # Get latest context for display\n",
    "#         latest_context = \"\\n\".join([chunk['metadata'][\"text\"] for chunk in query_pinecone(\n",
    "#             get_embedding(user_input)\n",
    "#         )][:3])  # Show top 3 context snippets\n",
    "        \n",
    "#         return \"\", new_history, latest_context\n",
    "\n",
    "#     # Component interactions\n",
    "#     submit_btn.click(\n",
    "#         handle_submit,\n",
    "#         [user_input, chat_history],\n",
    "#         [user_input, chat_history, context_display]\n",
    "#     ).then(\n",
    "#         lambda x: x,\n",
    "#         [chat_history],\n",
    "#         [chatbot]\n",
    "#     )\n",
    "\n",
    "#     undo_btn.click(\n",
    "#         lambda history: history[:-1] if history else [],\n",
    "#         [chat_history],\n",
    "#         [chat_history]\n",
    "#     ).then(\n",
    "#         lambda x: x,\n",
    "#         [chat_history],\n",
    "#         [chatbot]\n",
    "#     )\n",
    "\n",
    "#     clear_btn.click(\n",
    "#         lambda: [],\n",
    "#         None,\n",
    "#         [chat_history]\n",
    "#     ).then(\n",
    "#         lambda: ([], \"\"),\n",
    "#         None,\n",
    "#         [chatbot, context_display]\n",
    "#     )\n",
    "\n",
    "# interface.launch(share=True)\n",
    "# Just change the launch command to:\n",
    "#interface.launch(share=True, auth=(\"username\", \"password\"))  # Add basic auth\n",
    "\n",
    "\n",
    "# self hosting\n",
    "\n",
    "# # Run with:\n",
    "# interface.launch(\n",
    "#     server_name=\"0.0.0.0\",\n",
    "#     server_port=7860,\n",
    "#     show_error=True\n",
    "# )\n",
    "\n",
    "\n",
    "# ------------------------------------------- WORKING 3 Enter key submits user query -------------------------------------------\n",
    "# Initialize empty conversation history (list of tuples)\n",
    "conversation_history = []\n",
    "\n",
    "def process_user_query(user_query: str, conversation_history: list):\n",
    "    print(f\"User Query Tokens: {count_tokens(user_query)}\")\n",
    "\n",
    "    # Generate embedding and get relevant context\n",
    "    embedding = get_embedding(user_query)\n",
    "    relevant_chunks = query_pinecone(embedding)\n",
    "    context = \"\\n\".join(chunk['metadata'][\"text\"] for chunk in relevant_chunks)\n",
    "    print(\"CONTEXT:\", context)\n",
    "\n",
    "    # Format conversation history for the prompt\n",
    "    history_str = \"\\n\".join(\n",
    "        f\"User: {user}\\nCoach: {response}\" \n",
    "        for user, response in conversation_history\n",
    "    )\n",
    "\n",
    "    # Create structured prompt\n",
    "    prompt = f\"\"\"You are a knowledgeable and friendly coach. Follow these guidelines:\n",
    "    1. Provide clear, step-by-step explanations\n",
    "    2. Ask guiding questions to encourage critical thinking\n",
    "    3. Adapt to the student's knowledge level\n",
    "    4. Use examples from the provided context when relevant\n",
    "\n",
    "    Context from learning materials:\n",
    "    {context}\n",
    "\n",
    "    Conversation history:\n",
    "    {history_str}\n",
    "\n",
    "    New student question:\n",
    "    \"{user_query}\"\n",
    "\n",
    "    Provide a helpful response:\"\"\"\n",
    "\n",
    "    # Get LLM response\n",
    "    groq_response = query_groq(prompt)\n",
    "    print(f\"Response Tokens: {count_tokens(groq_response)}\")\n",
    "\n",
    "    # Return updated history with new interaction\n",
    "    return conversation_history + [(user_query, groq_response)]\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"# 🧑‍🏫 AI Coaching Assistant\")\n",
    "    gr.Markdown(\"Welcome! I'm here to help you learn. Type your question below.\")\n",
    "    \n",
    "    # State management\n",
    "    chat_history = gr.State(conversation_history)\n",
    "    \n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500)\n",
    "        with gr.Column(scale=0.5):\n",
    "            context_display = gr.Textbox(label=\"Relevant Context\", interactive=False)\n",
    "\n",
    "    user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type here...\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        undo_btn = gr.Button(\"Undo Last\")\n",
    "        clear_btn = gr.Button(\"Clear History\")\n",
    "\n",
    "    def handle_submit(user_input, history):\n",
    "        if not user_input.strip():\n",
    "            return gr.update(), history, \"\"\n",
    "        \n",
    "        # Process query and update history\n",
    "        new_history = process_user_query(user_input, history)\n",
    "        \n",
    "        # Get latest context for display\n",
    "        latest_context = \"\\n\".join([chunk['metadata'][\"text\"] for chunk in query_pinecone(\n",
    "            get_embedding(user_input)\n",
    "        )][:3])  # Show top 3 context snippets\n",
    "        \n",
    "        return \"\", new_history, latest_context\n",
    "\n",
    "    # Component interactions\n",
    "    submit_btn.click(\n",
    "        handle_submit,\n",
    "        [user_input, chat_history],\n",
    "        [user_input, chat_history, context_display]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "    \n",
    "    # Add submit on Enter key press\n",
    "    user_input.submit(\n",
    "        handle_submit,\n",
    "        [user_input, chat_history],\n",
    "        [user_input, chat_history, context_display]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "\n",
    "    undo_btn.click(\n",
    "        lambda history: history[:-1] if history else [],\n",
    "        [chat_history],\n",
    "        [chat_history]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        lambda: [],\n",
    "        None,\n",
    "        [chat_history]\n",
    "    ).then(\n",
    "        lambda: ([], \"\"),\n",
    "        None,\n",
    "        [chatbot, context_display]\n",
    "    )\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
