{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API pcsk_4bLR9o_3crxHE9zjHW76VdRnBPi2Xo794pQnKSifnRfQ9iQc6U3iqeqeyVEZ3RjBPYtoD4\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from tkinter import scrolledtext, messagebox\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "# from pinecone import Pinecone, ServerlessSpec\n",
    "import pinecone\n",
    "from pinecone import (\n",
    "    Pinecone,\n",
    "    ServerlessSpec,\n",
    "    CloudProvider,\n",
    "    AwsRegion,\n",
    "    VectorType\n",
    ")\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tkinter as tk\n",
    "import gradio as gr\n",
    "from typing import List, Tuple\n",
    "import concurrent.futures\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Important: Import pinecone-client properly\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "PINECONE_API = os.getenv(\"PINECONE_API\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "print(\"PINECONE_API\", PINECONE_API)\n",
    "\n",
    "\n",
    "# Groq API settings\n",
    "GROQ_EMBED_URL = \"https://api.groq.com/openai/v1/embeddings\"\n",
    "GROQ_CHAT_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "EMBEDDING_MODEL = \"llama3-405b-8192-embed\"\n",
    "LLM_MODEL = \"llama3-70b-8192\"\n",
    "\n",
    "\n",
    "# Configure headers for Groq API requests\n",
    "GROQ_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_4bLR9o_3crxHE9zjHW76VdRnBPi2Xo794pQnKSifnRfQ9iQc6U3iqeqeyVEZ3RjBPYtoD4\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API)\n",
    "print(PINECONE_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the index\n",
    "index = pc.Index(\"ai-coach\")\n",
    "# index = pc.Index(\"ahsan-400pg-pdf-doc-test\")\n",
    "\n",
    "embedding_model = AutoModel.from_pretrained(\n",
    "    'jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
    "\n",
    "\n",
    "# Function to generate embeddings without tokenization\n",
    "def get_embedding(data):\n",
    "    embeddings = embedding_model.encode(data).tolist()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Pinecone index using embeddings\n",
    "def query_pinecone(embedding):\n",
    "    # Use keyword arguments to pass the embedding and other parameters\n",
    "    result = index.query(vector=embedding, top_k=20, include_metadata=True)\n",
    "    return result['matches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Groq Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Groq LLM\n",
    "def query_groq(prompt: str) -> str:\n",
    "    response = requests.post(\n",
    "        GROQ_CHAT_URL,\n",
    "        headers=GROQ_HEADERS,\n",
    "        json={\n",
    "            \"model\": LLM_MODEL,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 8192  # max from groq website\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error querying Groq: {response.text}\")\n",
    "\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Tokenizer to count number of tokens\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v2-base-en\")\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    # Encode the text into tokens\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process User Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio GUI TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABC\\AppData\\Local\\Temp\\ipykernel_4516\\3839827934.py:210: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(height=500)\n",
      "D:\\Disrupt Labs\\AI Coach Project\\Rag-pipelines-experiments\\env\\Lib\\site-packages\\gradio\\layouts\\column.py:55: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://7cf80a17d17149e5a5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7cf80a17d17149e5a5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query Tokens: 4\n",
      "CONTEXT: Bank Name: nan Question: Which is the highest level of Maslow‚Äôs Hierarchy of Needs? Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Self-actualization Feedback 1: nan Answer 2: Acceptance Feedback 2: nan Answer 3: Belonging Feedback 3: nan Answer 4: Love Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: What is true about Maslow's Heirarchy of needs? Randomization (Yes/No): Yes Correct Answer Number: 2 Answer 1: Any need can be filled in any order Feedback 1: nan Answer 2: The basic needs at the base must be filled first Feedback 2: nan Answer 3: The needs at the top must be filled first Feedback 3: nan Answer 4: It is shaped like a square Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Maslow‚Äôs Hierarchy of Needs is a model for meeting ________ and is used as a reference point for patient care. Randomization (Yes/No): No Correct Answer Number: 3 Answer 1: Surgeon's Needs Feedback 1: nan Answer 2: Patient's family member's needs Feedback 2: nan Answer 3: human needs Feedback 3: nan Answer 4: None are Correct Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: According to Maslow‚Äôs Hierarchy of Needs, physiological needs are all of the following EXCEPT ________________. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Psychological Feedback 1: nan Answer 2: Biochemical Feedback 2: nan Answer 3: Mechanical Feedback 3: nan Answer 4: Physical Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: ________ is a model of human needs. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Maslow‚Äôs Hierarchy of Needs Feedback 1: nan Answer 2: Developmental Stages Model Feedback 2: nan Answer 3: Therapeutic Comminication Pyramid Feedback 3: nan Answer 4: The Food Pyramid Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Course Name: Introduction to Surgical Technology File Name: C1L5 Topic: Supporting the psychosocial needs of the patient Description: This lesson emphasizes the importance of addressing patients' psychosocial needs in surgery through empathy, active listening, and reassurance. It discusses common patient fears, the role of communication, and Maslow‚Äôs hierarchy of needs in understanding and supporting patients emotionally. Keywords: psychosocial needs, patient care, empathy, active listening, reassurance, Maslow‚Äôs hierarchy, surgical anxiety, therapeutic communication, patient fears, emotional support\n",
      "Bank Name: nan Question: A \"mixed message\" is the result of one's words not matching their _______ Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Body Language/Non-Verbal Communication Feedback 1: nan Answer 2: Cultural Norms Feedback 2: nan Answer 3: Role Feedback 3: nan Answer 4: Cultural Competence Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Law in most society is intended to protect __________. Randomization (Yes/No): No Correct Answer Number: 1 Answer 1: individuals Feedback 1: nan Answer 2: state officials Feedback 2: nan Answer 3: government officials Feedback 3: nan Answer 4: none are correct Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "C1L2\t-\tAsley\tHay\n",
      "(0:05\t-\t2:00)\n",
      "Hello,\tAshley\tHay\there\twith\tHealth\tTech\tAcademy,\tand\tI'm\tgoing\tto\tbe\thelping\tyou\talong\tyour\n",
      "journey\tthroughout\tthis\tcourse,\tjust\tgiving\tyou\ta\tlittle\tbit\tof\textra\tinfo\tand\trecapping\tsome\n",
      "content\tfrom\tthe\tmodules\tand\tthe\tlessons\tthat\tyou're\talready\tgoing\tthrough.\tSo\tI\thope\tthat\n",
      "you\tare\tenjoying\tthis\tcourse\tso\tfar.\tI\tknow\tthat\tin\tthe\tprior\tlesson,\twe\tkind\tof\tdug\tinto\ta\tlittle\tbit\n",
      "about\tthe\tprofession\tin\tgeneral\tand\twhat\tto\texpect,\tbut\tI\tdid\twant\tto\thighlight\ta\tfew\treally\n",
      "important\tpieces\tof\tinformation\tregarding\tcommunication\tand\tteamwork.\n",
      "I\tmyself\thave\tbeen\tan\toncology\tnurse\tfor\talmost\t20\tyears,\tand\tI\tcan\ttell\tyou\tI've\tworked\tin\ta\n",
      "variety\tof\tsettings,\tand\tit\tdoesn't\tmatter\twhat\tkind\tof\thealthcare\tprovider\tyou\tare,\tif\tthere\tis,\n",
      "Bank Name: nan Question: ________ is the response to a message and is a component of effective communication. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Feedback Feedback 1: nan Answer 2: Aggression Feedback 2: nan Answer 3: Abuse Feedback 3: nan Answer 4: Harrassment Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Suzie has taken the CST examination and passed. For Suzie to keep her certification without retaking the examination, she must do one of the following __________. Randomization (Yes/No): Yes Correct Answer Number: 2 Answer 1: attend the national conference Feedback 1: nan Answer 2: maintain continuing education (CE) credits Feedback 2: nan Answer 3: nothing Feedback 3: nan Answer 4: attend all state meetings Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: A wrong, independent of contract law violations, perpetrated by one person against another person or person‚Äôs property that can be compensable by money damages is known as ___________. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Tort Feedback 1: nan Answer 2: slander Feedback 2: nan Answer 3: damages Feedback 3: nan Answer 4: negligence Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Communication \n",
      "and Teamwork\n",
      "Bank Name: nan Question: Even if the sender does not wish to express his or her true feelings about the message, these feelings will probably be conveyed by ________. Randomization (Yes/No): Yes Correct Answer Number: 3 Answer 1: aggressive behavior Feedback 1: nan Answer 2: assertiveness Feedback 2: nan Answer 3: body language Feedback 3: nan Answer 4: gossip and rumors Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Many health care workers are surprised to find that the greatest challenge in their work is not the work itself but the ________ of the workplace. Randomization (Yes/No): Yes Correct Answer Number: 4 Answer 1: stress Feedback 1: nan Answer 2: acceptable social distances Feedback 2: nan Answer 3: location Feedback 3: nan Answer 4: interactions and social climate Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: In order to have good communication, it must be understood by the receiver.  The way the reciever can show that the message was understood is known as ______ Randomization (Yes/No): Yes Correct Answer Number: 2 Answer 1: Tone Feedback 1: nan Answer 2: Feedback Feedback 2: nan Answer 3: Expression Feedback 3: nan Answer 4: Assertiveness Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Self-actualization is one‚Äôs ability to express and achieve ________ goals. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Personal Feedback 1: nan Answer 2: Professional Feedback 2: nan Answer 3: FInancial Feedback 3: nan Answer 4: Societal Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: _______________ is the ability to communicate effectively with people of different cultures and subcultures within populations. Randomization (Yes/No): Yes Correct Answer Number: 1 Answer 1: Cultural Competence Feedback 1: nan Answer 2: cultural reference Feedback 2: nan Answer 3: culture guidelines Feedback 3: nan Answer 4: culture club Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: If the reciever does not completely understand the message being sent, they may ask for _______. Randomization (Yes/No): Yes Correct Answer Number: 3 Answer 1: Feedback Feedback 1: nan Answer 2: Tone Feedback 2: nan Answer 3: Clarification Feedback 3: nan Answer 4: Assertiveness Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Bank Name: nan Question: Communication is a two-way process between the ________. Randomization (Yes/No): Yes Correct Answer Number: 2 Answer 1: ST and Patient Feedback 1: nan Answer 2: sender and reciever Feedback 2: nan Answer 3: surgeon and circulator Feedback 3: nan Answer 4: none are correct Feedback 4: nan Answer 5: nan Feedback 5: nan Answer n: nan Feedback n: nan\n",
      "Response Toke   ns: 90\n"
     ]
    }
   ],
   "source": [
    "# system_message = f\"\"\"\n",
    "#     You are a knowledgeable and friendly coach. Your goal is to help students understand concepts in a detailed and easy-to-understand manner.\n",
    "#     Be patient, ask guiding questions, and provide step-by-step explanations where needed. Adapt your responses to the student's knowledge level\n",
    "#     and help them build confidence in their learning. Refer relevant material to the student and encourage them to explore further.\n",
    "\n",
    "#     Based on the context and the student's question, provide a thoughtful and detailed explanation. Encourage them to think about the topic and\n",
    "#     offer further guidance if needed.\n",
    "#     \"\"\"\n",
    "\n",
    "# def gradio_interface(prompt,history =[]):\n",
    "#     output = process_user_query(prompt,history)\n",
    "#     history.append((prompt,output))\n",
    "#     return history\n",
    "\n",
    "# gr.Interface(fn=gradio_interface, inputs= ['text',\"state\"], outputs=[\"chatbot\",\"state\"]).launch(debug=True,share=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------- WORKING 1 -------------------------------------------\n",
    "\n",
    "# # Function to be used by Gradio for handling the query\n",
    "# def gradio_process(user_query):\n",
    "#     response = process_user_query(user_query, conversation_history)\n",
    "#     return response\n",
    "\n",
    "# # Create Gradio interface\n",
    "# interface = gr.Interface(fn=gradio_process, inputs=\"text\", outputs=\"text\", title=\"RAG-based Coaching System\")\n",
    "\n",
    "# # Launch Gradio app\n",
    "# interface.launch()\n",
    "# ------------------------------------------- WORKING 2 -------------------------------------------\n",
    "\n",
    "# Initialize empty conversation history (list of tuples)\n",
    "# conversation_history = []\n",
    "\n",
    "# def process_user_query(user_query: str, conversation_history: list):\n",
    "#     print(f\"User Query Tokens: {count_tokens(user_query)}\")\n",
    "\n",
    "#     # Generate embedding and get relevant context\n",
    "#     embedding = get_embedding(user_query)\n",
    "#     relevant_chunks = query_pinecone(embedding)\n",
    "#     context = \"\\n\".join(chunk['metadata'][\"text\"] for chunk in relevant_chunks)\n",
    "#     print(\"CONTEXT:\", context)\n",
    "\n",
    "#     # Format conversation history for the prompt\n",
    "#     history_str = \"\\n\".join(\n",
    "#         f\"User: {user}\\nCoach: {response}\"\n",
    "#         for user, response in conversation_history\n",
    "#     )\n",
    "\n",
    "#     # Create structured prompt\n",
    "#     prompt = f\"\"\"You are a knowledgeable and friendly coach. Follow these guidelines:\n",
    "#     1. Provide clear, step-by-step explanations\n",
    "#     2. Ask guiding questions to encourage critical thinking\n",
    "#     3. Adapt to the student's knowledge level\n",
    "#     4. Use examples from the provided context when relevant\n",
    "\n",
    "#     Context from learning materials:\n",
    "#     {context}\n",
    "\n",
    "#     Conversation history:\n",
    "#     {history_str}\n",
    "\n",
    "#     New student question:\n",
    "#     \"{user_query}\"\n",
    "\n",
    "#     Provide a helpful response:\"\"\"\n",
    "\n",
    "#     # Get LLM response\n",
    "#     groq_response = query_groq(prompt)\n",
    "#     print(f\"Response Tokens: {count_tokens(groq_response)}\")\n",
    "\n",
    "#     # Return updated history with new interaction\n",
    "#     return conversation_history + [(user_query, groq_response)]\n",
    "\n",
    "# # Gradio Interface\n",
    "# with gr.Blocks() as interface:\n",
    "#     gr.Markdown(\"# üßë‚Äçüè´ AI Coaching Assistant\")\n",
    "#     gr.Markdown(\"Welcome! I'm here to help you learn. Type your question below.\")\n",
    "\n",
    "#     # State management\n",
    "#     chat_history = gr.State(conversation_history)\n",
    "\n",
    "#     with gr.Row():\n",
    "#         chatbot = gr.Chatbot(height=500)\n",
    "#         with gr.Column(scale=0.5):\n",
    "#             context_display = gr.Textbox(label=\"Relevant Context\", interactive=False)\n",
    "\n",
    "#     user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type here...\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "#         undo_btn = gr.Button(\"Undo Last\")\n",
    "#         clear_btn = gr.Button(\"Clear History\")\n",
    "\n",
    "#     def handle_submit(user_input, history):\n",
    "#         if not user_input.strip():\n",
    "#             return gr.update(), history, \"\"\n",
    "\n",
    "#         # Process query and update history\n",
    "#         new_history = process_user_query(user_input, history)\n",
    "\n",
    "#         # Get latest context for display\n",
    "#         latest_context = \"\\n\".join([chunk['metadata'][\"text\"] for chunk in query_pinecone(\n",
    "#             get_embedding(user_input)\n",
    "#         )][:3])  # Show top 3 context snippets\n",
    "\n",
    "#         return \"\", new_history, latest_context\n",
    "\n",
    "#     # Component interactions\n",
    "#     submit_btn.click(\n",
    "#         handle_submit,\n",
    "#         [user_input, chat_history],\n",
    "#         [user_input, chat_history, context_display]\n",
    "#     ).then(\n",
    "#         lambda x: x,\n",
    "#         [chat_history],\n",
    "#         [chatbot]\n",
    "#     )\n",
    "\n",
    "#     undo_btn.click(\n",
    "#         lambda history: history[:-1] if history else [],\n",
    "#         [chat_history],\n",
    "#         [chat_history]\n",
    "#     ).then(\n",
    "#         lambda x: x,\n",
    "#         [chat_history],\n",
    "#         [chatbot]\n",
    "#     )\n",
    "\n",
    "#     clear_btn.click(\n",
    "#         lambda: [],\n",
    "#         None,\n",
    "#         [chat_history]\n",
    "#     ).then(\n",
    "#         lambda: ([], \"\"),\n",
    "#         None,\n",
    "#         [chatbot, context_display]\n",
    "#     )\n",
    "\n",
    "# interface.launch(share=True)\n",
    "# Just change the launch command to:\n",
    "# interface.launch(share=True, auth=(\"username\", \"password\"))  # Add basic auth\n",
    "\n",
    "\n",
    "# self hosting\n",
    "\n",
    "# # Run with:\n",
    "# interface.launch(\n",
    "#     server_name=\"0.0.0.0\",\n",
    "#     server_port=7860,\n",
    "#     show_error=True\n",
    "# )\n",
    "\n",
    "\n",
    "# ------------------------------------------- WORKING 3 Enter key submits user query -------------------------------------------\n",
    "# Initialize empty conversation history (list of tuples)\n",
    "conversation_history = []\n",
    "\n",
    "\n",
    "def process_user_query(user_query: str, conversation_history: list):\n",
    "    print(f\"User Query Tokens: {count_tokens(user_query)}\")\n",
    "\n",
    "    # Generate embedding and get relevant context\n",
    "    embedding = get_embedding(user_query)\n",
    "    relevant_chunks = query_pinecone(embedding)\n",
    "    context = \"\\n\".join(chunk['metadata'][\"text\"] for chunk in relevant_chunks)\n",
    "    print(\"CONTEXT:\", context)\n",
    "\n",
    "    # Format conversation history for the prompt\n",
    "    history_str = \"\\n\".join(\n",
    "        f\"User: {user}\\nCoach: {response}\"\n",
    "        for user, response in conversation_history\n",
    "    )\n",
    "\n",
    "    # Create structured prompt\n",
    "    prompt = f\"\"\"You are an expert, knowledgeable, and friendly coach. Follow these guidelines carefully:\n",
    "\n",
    "1. Provide clear, step-by-step explanations to ensure deep understanding.\n",
    "2. Use chain-of-thought reasoning to thoroughly evaluate the provided context before responding.\n",
    "3. Ask guiding questions to encourage critical thinking.\n",
    "4. Adapt your explanation to match the student's knowledge level.\n",
    "5. Strictly use terminologies provided in the given context.\n",
    "6. Provide short, ideal examples (2-3) to illustrate your points clearly.\n",
    "7. Only answer based on the provided context‚Äîdo not speculate or include external information.\n",
    "8. Explicitly cite the sources from the context in your responses.\n",
    "9. Perform sentiment analysis based on conversation history and user queries to adapt your responses empathetically and effectively.\n",
    "\n",
    "Context from learning materials:\n",
    "{context}\n",
    "\n",
    "Conversation history:\n",
    "{history_str}\n",
    "\n",
    "New student question:\n",
    "\"{user_query}\"\n",
    "\n",
    "Provide a helpful, structured response that meets the above criteria.\n",
    "\n",
    "(Note: The following examples are only provided for your reference to demonstrate an effective response format):\n",
    "\n",
    "Question: How long will the average externship take to complete?\n",
    "Answer: 125 surgical cases ‚Äì typically 6 months to 1 year.\n",
    "\n",
    "Question: What should I focus on when studying anatomy, physiology, and medical terminology?\n",
    "Answer: Focus specifically on content related to surgical procedures, emphasizing body systems, terminology, and physiological functions most relevant to surgery.\n",
    "\n",
    "Question: What‚Äôs the best way to study and memorize surgical instrumentation?\n",
    "Answer: First, understand the National Center for Competency Testing (NCCT) exam expectations regarding instruments. Refer to official NCCT guidelines and utilize platforms such as Quizlet and ProProfs for visual memorization and repetition.\n",
    "\n",
    "Provide a thoughtful and contextually accurate response now:\"\"\"\n",
    "    # Get LLM response\n",
    "    groq_response = query_groq(prompt)\n",
    "    print(f\"Response Toke   ns: {count_tokens(groq_response)}\")\n",
    "\n",
    "    # Return updated history with new interaction\n",
    "    return conversation_history + [(user_query, groq_response)]\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"# üßë‚Äçüè´ AI Coaching Assistant\")\n",
    "    gr.Markdown(\"Welcome! I'm here to help you learn. Type your question below.\")\n",
    "\n",
    "    # State management\n",
    "    chat_history = gr.State(conversation_history)\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500)\n",
    "        with gr.Column(scale=0.5):\n",
    "            context_display = gr.Textbox(\n",
    "                label=\"Relevant Context\", interactive=False)\n",
    "\n",
    "    user_input = gr.Textbox(label=\"Your Question\", placeholder=\"Type here...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        undo_btn = gr.Button(\"Undo Last\")\n",
    "        clear_btn = gr.Button(\"Clear History\")\n",
    "\n",
    "    def handle_submit(user_input, history):\n",
    "        if not user_input.strip():\n",
    "            return gr.update(), history, \"\"\n",
    "\n",
    "        # Process query and update history\n",
    "        new_history = process_user_query(user_input, history)\n",
    "\n",
    "        # Get latest context for display\n",
    "        latest_context = \"\\n\".join([chunk['metadata'][\"text\"] for chunk in query_pinecone(\n",
    "            get_embedding(user_input)\n",
    "        )][:3])  # Show top 3 context snippets\n",
    "\n",
    "        return \"\", new_history, latest_context\n",
    "\n",
    "    # Component interactions\n",
    "    submit_btn.click(\n",
    "        handle_submit,\n",
    "        [user_input, chat_history],\n",
    "        [user_input, chat_history, context_display]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "\n",
    "    # Add submit on Enter key press\n",
    "    user_input.submit(\n",
    "        handle_submit,\n",
    "        [user_input, chat_history],\n",
    "        [user_input, chat_history, context_display]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "\n",
    "    undo_btn.click(\n",
    "        lambda history: history[:-1] if history else [],\n",
    "        [chat_history],\n",
    "        [chat_history]\n",
    "    ).then(\n",
    "        lambda x: x,\n",
    "        [chat_history],\n",
    "        [chatbot]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        lambda: [],\n",
    "        None,\n",
    "        [chat_history]\n",
    "    ).then(\n",
    "        lambda: ([], \"\"),\n",
    "        None,\n",
    "        [chatbot, context_display]\n",
    "    )\n",
    "\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
