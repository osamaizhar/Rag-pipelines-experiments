{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtextwrap\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PyPDF2'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Important: Import pinecone-client properly\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "PINECONE_API = os.getenv(\"PINECONE_API\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "print(\"PINECONE_API\", PINECONE_API)\n",
    "\n",
    "\n",
    "\n",
    "# Groq API settings\n",
    "GROQ_EMBED_URL = \"https://api.groq.com/openai/v1/embeddings\"\n",
    "GROQ_CHAT_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "EMBEDDING_MODEL = \"llama3-405b-8192-embed\"\n",
    "LLM_MODEL = \"llama3-70b-8192\"\n",
    "\n",
    "\n",
    "# Configure headers for Groq API requests\n",
    "GROQ_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n",
      "Advanced encoding /SymbolSetEncoding not implemented yet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Nitro Pro  (11. 0. 1. 10)', 'creator': 'Nitro Pro  (11. 0. 1. 10)', 'creationdate': '2025-03-09T10:44:04+00:00', 'moddate': '2025-03-09T15:44:28+05:00', 'title': 'PowerPoint Presentation', 'author': 'James Kurose', 'source': 'D:\\\\Disrupt Labs\\\\Rag Experiments\\\\env\\\\Rag-pipelines-experiments\\\\data\\\\4.1_video_slides.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='Network Layer:\\nData Plane\\n\\uf0a7 Overview of Network Layer\\n\\uf0a7 What’s Inside a Router?\\n\\uf0a7 The Internet Protocol: IPv4, Addressing, NAT\\nIPv6\\n\\uf0a7 Generalized Forwarding and SDN\\n\\uf0a7 Middleboxes\\n\\uf0a7 Summary\\nCOMPSCI 453 Computer Networks\\nProfessor Jim Kurose\\nCollege of Information and Computer Sciences\\nUniversity of Massachusetts\\nClass textbook:\\nComputer Networking: A Top-\\nDown Approach (8th ed.)\\nJ.F. Kurose, K.W . Ross\\nPearson, 2020\\nhttp://gaia.cs.umass.edu/kurose_ross')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "\n",
    "documents = load_documents()\n",
    "documents[0]\n",
    "\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "#     \"\"\"Extract text from a PDF file.\"\"\"\n",
    "#     with open(pdf_path, 'r') as file:\n",
    "#         pdf_reader = PyPDF2.PdfReader(file)\n",
    "#         text = \"\"\n",
    "#         for page_num in range(len(pdf_reader.pages)):\n",
    "#             page = pdf_reader.pages[page_num]\n",
    "#             text += page.extract_text() + \"\\n\"\n",
    "#     return text\n",
    "# extract_text_from_pdf(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitting \\ Chunking using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Nitro Pro  (11. 0. 1. 10)', 'creator': 'Nitro Pro  (11. 0. 1. 10)', 'creationdate': '2025-03-09T10:44:04+00:00', 'moddate': '2025-03-09T15:44:28+05:00', 'title': 'PowerPoint Presentation', 'author': 'James Kurose', 'source': 'D:\\\\Disrupt Labs\\\\Rag Experiments\\\\env\\\\Rag-pipelines-experiments\\\\data\\\\4.1_video_slides.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='Network Layer:\\nData Plane\\n\\uf0a7 Overview of Network Layer\\n\\uf0a7 What’s Inside a Router?\\n\\uf0a7 The Internet Protocol: IPv4, Addressing, NAT\\nIPv6\\n\\uf0a7 Generalized Forwarding and SDN\\n\\uf0a7 Middleboxes\\n\\uf0a7 Summary\\nCOMPSCI 453 Computer Networks\\nProfessor Jim Kurose\\nCollege of Information and Computer Sciences\\nUniversity of Massachusetts\\nClass textbook:\\nComputer Networking: A Top-\\nDown Approach (8th ed.)\\nJ.F. Kurose, K.W . Ross\\nPearson, 2020\\nhttp://gaia.cs.umass.edu/kurose_ross')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap  = 80,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False # considers separators like '\\n\\n'if true\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "\n",
    "chunks = split_documents(documents)\n",
    "chunks[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pinecone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m         pinecone.create_index(\n\u001b[32m      9\u001b[39m             name=index_name,\n\u001b[32m     10\u001b[39m             dimension=\u001b[32m1024\u001b[39m,  \u001b[38;5;66;03m# Updated to match your index dimension\u001b[39;00m\n\u001b[32m     11\u001b[39m             metric=\u001b[33m\"\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m             spec={\u001b[33m\"\u001b[39m\u001b[33mserverless\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mcloud\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maws\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mregion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mus-east-1\u001b[39m\u001b[33m\"\u001b[39m}}  \u001b[38;5;66;03m# Updated to match your configuration\u001b[39;00m\n\u001b[32m     13\u001b[39m         )\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pinecone.Index(index_name)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43minit_pinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest-index\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36minit_pinecone\u001b[39m\u001b[34m(index_name)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_pinecone\u001b[39m(index_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize Pinecone and create index if it doesn't exist.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mpinecone\u001b[49m.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Check if index exists, if not create it\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pinecone.list_indexes():\n",
      "\u001b[31mNameError\u001b[39m: name 'pinecone' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure Pinecone\n",
    "def init_pinecone(index_name: str) -> None:\n",
    "    \"\"\"Initialize Pinecone and create index if it doesn't exist.\"\"\"\n",
    "    pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "    \n",
    "    # Check if index exists, if not create it\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        pinecone.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1024,  # Updated to match your index dimension\n",
    "            metric=\"cosine\",\n",
    "            spec={\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}}  # Updated to match your configuration\n",
    "        )\n",
    "    return pinecone.Index(index_name)\n",
    "\n",
    "init_pinecone(\"test-index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Embeddings Via OpenAI API of groq inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str):\n",
    "    \"\"\"Get embedding for a text using Groq API.\"\"\"\n",
    "    response = requests.post(\n",
    "        GROQ_EMBED_URL,\n",
    "        headers=GROQ_HEADERS,\n",
    "        json={\n",
    "            \"model\": EMBEDDING_MODEL,\n",
    "            \"input\": text\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error getting embedding: {response.text}\")\n",
    "    \n",
    "    # Get embedding and truncate to match Pinecone dimension if needed\n",
    "    embedding = response.json()[\"data\"][0][\"embedding\"]\n",
    "    if len(embedding) > 1024:  # Ensure embedding matches your Pinecone dimension\n",
    "        embedding = embedding[:1024]\n",
    "        \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_chunks_to_pinecone(index, chunks: List[str], pdf_name: str) -> None:\n",
    "    \"\"\"Convert chunks to embeddings and upsert to Pinecone.\"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Progress indicator\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "        \n",
    "        embedding = get_embedding(chunk)\n",
    "        vectors.append({\n",
    "            \"id\": f\"{pdf_name}-chunk-{i}\",\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\n",
    "                \"text\": chunk,\n",
    "                \"source\": pdf_name,\n",
    "                \"chunk_id\": i\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Batch upsert every 100 vectors or at the end\n",
    "        if len(vectors) >= 100 or i == len(chunks) - 1:\n",
    "            index.upsert(vectors=vectors)\n",
    "            vectors = []\n",
    "    \n",
    "    print(f\"Successfully uploaded {len(chunks)} chunks to Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_groq(prompt: str) -> str:\n",
    "    \"\"\"Query Groq LLM with a prompt.\"\"\"\n",
    "    response = requests.post(\n",
    "        GROQ_CHAT_URL,\n",
    "        headers=GROQ_HEADERS,\n",
    "        json={\n",
    "            \"model\": LLM_MODEL,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_tokens\": 1024\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error querying Groq: {response.text}\")\n",
    "    \n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pinecone(index, query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"Search Pinecone for similar chunks based on the query.\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return results.matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: List[Dict]) -> str:\n",
    "    \"\"\"Generate a response based on the query and retrieved context.\"\"\"\n",
    "    # Create a prompt with context\n",
    "    context_text = \"\\n\\n\".join([match[\"metadata\"][\"text\"] for match in context])\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful assistant that answers questions based on provided context. \n",
    "    \n",
    "    CONTEXT:\n",
    "    {context_text}\n",
    "    \n",
    "    QUESTION:\n",
    "    {query}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    - Answer the question based only on the provided context\n",
    "    - If the answer is not in the context, say \"I don't have enough information to answer that question.\"\n",
    "    - Cite specific parts of the context that support your answer\n",
    "    - Be concise and clear\n",
    "    \n",
    "    ANSWER:\"\"\"\n",
    "    \n",
    "    return query_groq(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process pdf document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_document(pdf_path: str, index_name: str) -> None:\n",
    "    \"\"\"Process a PDF document and store in Pinecone.\"\"\"\n",
    "    # Initialize Pinecone\n",
    "    index = init_pinecone(index_name)\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    print(f\"Extracting text from {pdf_path}...\")\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Split text into chunks\n",
    "    print(\"Splitting text into chunks...\")\n",
    "    chunks = split_text(pdf_text)\n",
    "    \n",
    "    # Get PDF filename for identifying the source\n",
    "    pdf_name = os.path.basename(pdf_path)\n",
    "    \n",
    "    # Upsert chunks to Pinecone\n",
    "    print(f\"Upserting {len(chunks)} chunks to Pinecone...\")\n",
    "    upsert_chunks_to_pinecone(index, chunks, pdf_name)\n",
    "    \n",
    "    print(f\"Successfully processed {pdf_path} and stored in Pinecone index '{index_name}'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query: str, index_name: str) -> str:\n",
    "    \"\"\"Answer a query using the RAG pipeline.\"\"\"\n",
    "    # Initialize Pinecone\n",
    "    index = init_pinecone(index_name)\n",
    "    \n",
    "    # Search for relevant chunks\n",
    "    print(f\"Searching for relevant context for: '{query}'\")\n",
    "    matches = search_pinecone(index, query)\n",
    "    \n",
    "    if not matches:\n",
    "        return \"No relevant information found in the documents.\"\n",
    "    \n",
    "    # Generate response using Groq LLM\n",
    "    print(\"Generating response...\")\n",
    "    response = generate_response(query, matches)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--pdf PDF] [--query QUERY] [--index INDEX]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\Osama\\AppData\\Roaming\\jupyter\\runtime\\kernel-v311f1b8fae0eaad2f829c880752cf0ae8a9213684.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
